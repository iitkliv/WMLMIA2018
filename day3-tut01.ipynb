{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMLMIA 2018\n",
    "## Day 3: Medical Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from pylab import *\n",
    "import pickle\n",
    "from skimage import feature\n",
    "import struct\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path of data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'data/day4/'\n",
    "classes = os.listdir(dataPath+'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros((300,50,50),dtype=np.uint8)\n",
    "count = 0\n",
    "for c in classes:\n",
    "    list1 =os.listdir(dataPath+'train/'+c)\n",
    "    for f in list1:\n",
    "        train_data[count,:] = np.array(Image.open(dataPath+'train/'+c+'/'+f).resize((50,50)))\n",
    "        count += 1\n",
    "\n",
    "    \n",
    "test_data = np.zeros((100,50,50),dtype=np.uint8)\n",
    "count = 0\n",
    "for c in classes:\n",
    "    list1 =os.listdir(dataPath+'val/'+c)\n",
    "    for f in list1:\n",
    "        test_data[count,:] = np.array(Image.open(dataPath+'val/'+c+'/'+f).resize((50,50)))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test labels\n",
    "train_label = np.zeros(len(train_data))\n",
    "train_label[150:] = 1\n",
    "test_label = np.zeros(len(test_data))\n",
    "test_label[50:] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_greycoHomFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='homogeneity') for x in list(train_data)]\n",
    "train_greycoConFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='contrast') for x in list(train_data)]\n",
    "train_greycoEnFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='energy') for x in list(train_data)]\n",
    "train_greycoCorrFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='correlation') for x in list(train_data)]\n",
    "train_hogFeat = [feature.hog(x, orientations=2, pixels_per_cell=(5,5)) for x in list(train_data)]\n",
    "# train_lbpFeat = [feature.local_binary_pattern(x, 5, 3) for x in list(train_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greycoHomFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='homogeneity') for x in list(test_data)]\n",
    "test_greycoConFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='contrast') for x in list(test_data)]\n",
    "test_greycoEnFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='energy') for x in list(test_data)]\n",
    "test_greycoCorrFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='correlation') for x in list(test_data)]\n",
    "test_hogFeat = [feature.hog(x, orientations=2, pixels_per_cell=(5,5)) for x in list(test_data)]\n",
    "# test_lbpFeat = [feature.local_binary_pattern(x, 5, 3) for x in list(test_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_greycoHomFeat[0][0].shape)\n",
    "print(train_greycoConFeat[0][0].shape)\n",
    "print(train_greycoEnFeat[0][0].shape)\n",
    "print(train_greycoCorrFeat[0][0].shape)\n",
    "print(train_hogFeat[0].shape)\n",
    "# print(train_lbpFeat[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "trainFeat = np.zeros((300,1156),dtype=float)\n",
    "for num in range(300):    \n",
    "    trainFeat[num][:] = np.concatenate((train_greycoHomFeat[num].reshape(1,),train_greycoConFeat[num].reshape(1,),\n",
    "                            train_greycoEnFeat[num].reshape(1,),train_greycoCorrFeat[num].reshape(1,),\n",
    "                                        train_hogFeat[num].reshape(1152,)),axis=0)#,train_data[num].reshape(50*50)),axis=0)#,train_data[num].reshape(50*50)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "testFeat = np.zeros((100,1156),dtype=float)\n",
    "for num in range(100):    \n",
    "    testFeat[num][:] = np.concatenate((test_greycoHomFeat[num].reshape(1,),test_greycoConFeat[num].reshape(1,),\n",
    "                            test_greycoEnFeat[num].reshape(1,),test_greycoCorrFeat[num].reshape(1,),\n",
    "                                        test_hogFeat[num].reshape(1152,)),axis=0)#,test_lbpFeat[num].reshape(50*50),axis=0)#,test_data[num].reshape(50*50)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeat_scaled = preprocessing.scale(trainFeat)\n",
    "testFeat_scaled = preprocessing.scale(testFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "trainFeat_scaled, train_label = shuffle(trainFeat_scaled,train_label, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron\n",
    "sklearn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,50,), max_iter=200, alpha=1e-4,\n",
    "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=1e-3) #alpha - L regularization parameteer\n",
    "nn.fit(trainFeat_scaled, train_label)       \n",
    "prediction = nn.predict(testFeat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nn.loss_curve_)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: %f\" % nn.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % nn.score(testFeat_scaled, test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "sklearn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='sigmoid') # SVM classifier\n",
    "clf.fit(trainFeat_scaled,train_label)\n",
    "svm_prediction = clf.predict(testFeat_scaled)\n",
    "\n",
    "print(\"Training set score: %f\" % clf.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % clf.score(testFeat_scaled, test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "sklearn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "rf = RF(n_estimators=50)\n",
    "rf.fit(trainFeat_scaled,train_label)\n",
    "print(\"Training set score: %f\" % rf.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % rf.score(testFeat_scaled, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
