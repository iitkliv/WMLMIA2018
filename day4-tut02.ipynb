{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMLMIA 2018\n",
    "## Tutorial 2: Ultrasound Image Classification using Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import struct\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from random import shuffle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation to be applied on the input images\n",
    "input_transform = transforms.Compose([transforms.Resize(64),transforms.CenterCrop(64),transforms.ToTensor()])\n",
    "# Creating pytorch dataset \n",
    "trainDataset = ImageFolder('data/day4/train/', transform=input_transform)\n",
    "valDataset = ImageFolder('data/day4/val/', transform=input_transform)\n",
    "# Creating dataloader\n",
    "BatchSize = 32\n",
    "trainLoader = DataLoader(trainDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)\n",
    "valLoader = DataLoader(valDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Autoencoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64*64*3, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.ReLU())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 64*64*3),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimization technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Mean Squared Error \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.5, momentum=0.9) # Stochastic Gradient Descent\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-3) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the autoencoder for representaion learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "for epoch in range(iterations):   \n",
    "    net.train(True) # For training\n",
    "    runningLoss = 0\n",
    "    for data in trainLoader:\n",
    "        inputs,_  = data # Labels are not required     \n",
    "        inputs = inputs.view(-1,64*64*3)\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs).cuda()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        # Initialize the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Feed forward the input data through the network\n",
    "        outputs = net(inputs)       \n",
    "        # Compute the error/loss\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # Backpropagate the loss to compute gradients\n",
    "        loss.backward()\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.data[0]\n",
    "    # Printing average loss per epoch\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,runningLoss/\n",
    "                                                                (len(trainDataset)/BatchSize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the autoencoder for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the decoder module from the autoencoder\n",
    "new_classifier = nn.Sequential(*list(net.children())[:-1])\n",
    "net = new_classifier\n",
    "# Adding linear layer for 2-class classification problem\n",
    "net.add_module('classifier', nn.Sequential(nn.Linear(100, 2)))\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "# Copying initial weights  for visualization\n",
    "cll_weights = copy.deepcopy(net[0][0].weight.data)\n",
    "init_classifier_weights = copy.deepcopy(net.classifier[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-Likelihood\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4, momentum=0.9) # Stochastic gradient descent\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-4) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "trainLoss = []\n",
    "testAcc = []\n",
    "start = time.time()\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data\n",
    "        inputs = inputs.view(-1,64*64*3)\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Feed-forward input data through the network\n",
    "        outputs = net(inputs)\n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs,dim=1), labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.item()\n",
    "    avgTrainLoss = runningLoss/300\n",
    "    trainLoss.append(avgTrainLoss)\n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.train(False) # For testing\n",
    "    correct = 0\n",
    "    for data in valLoader:\n",
    "        inputs,labels = data\n",
    "        inputs = inputs.view(-1,64*64*3)    \n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.cpu()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "    avgTestAcc = correct.numpy()/100.0\n",
    "    testAcc.append(avgTestAcc)    \n",
    " \n",
    "    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Testing Acc: {:.3f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,avgTestAcc*100,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))\n",
    "\n",
    "# Plotting training loss vs Epochs\n",
    "fig1 = plt.figure(1)        \n",
    "plt.plot(range(epoch+1),trainLoss,'r-',label='train')        \n",
    "if epoch==0:\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Training loss')   \n",
    "# Plotting testing accuracy vs Epochs\n",
    "fig2 = plt.figure(2)        \n",
    "plt.plot(range(epoch+1),testAcc,'g-',label='test')        \n",
    "if epoch==0:\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Testing accuracy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
